# app/model.py
import os
import requests
import torch

MODEL_URL  = os.getenv("MODEL_URL")   # Supabase public URL
MODEL_PATH = "model.pt"
DEVICE = "cpu"

_MODEL = None


def download_model():
    if os.path.exists(MODEL_PATH):
        print("üì¶ Model already exists")
        return

    if not MODEL_URL:
        raise RuntimeError("‚ùå MODEL_URL is not set")

    print(f"‚¨áÔ∏è Downloading model from: {MODEL_URL}")

    with requests.get(MODEL_URL, stream=True, timeout=120) as r:
        r.raise_for_status()

        with open(MODEL_PATH, "wb") as f:
            for chunk in r.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)

    # üîç sanity check
    size_mb = os.path.getsize(MODEL_PATH) / (1024 * 1024)
    print(f"‚úÖ Model downloaded ({size_mb:.2f} MB)")

    if size_mb < 1:
        raise RuntimeError("‚ùå Model file looks corrupted (too small)")


def load_model():
    download_model()

    print("üß† Loading TorchScript model...")
    model = torch.jit.load(MODEL_PATH, map_location=DEVICE)
    model.eval()
    print("‚úÖ Model loaded")
    return model


def get_model():
    global _MODEL
    if _MODEL is None:
        _MODEL = load_model()
    return _MODEL
