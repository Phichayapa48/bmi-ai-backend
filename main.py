from fastapi import FastAPI, UploadFile, File
from PIL import Image
import io
import traceback
import torch

from app.model import get_model
from app.utils import preprocess_image
from app.face_utils import detect_and_crop_face
from app.quality_check import quality_check

BMI_STATUS_TH = {
    "under": "‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏Å‡∏ì‡∏ë‡πå",
    "normal": "‡∏™‡∏°‡∏™‡πà‡∏ß‡∏ô",
    "over": "‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏Å‡∏ì‡∏ë‡πå"
}

app = FastAPI()

# =========================
# GLOBAL MODEL
# =========================
model = None

# =========================
# CLASS CONFIG (‡∏ï‡∏£‡∏á‡∏ï‡∏≠‡∏ô train)
# =========================
BMI_LABELS = {
    0: "under",
    1: "normal",
    2: "over"
}

# =========================
# HEALTH CHECK
# =========================
@app.get("/")
def health():
    return {"status": "ok", "service": "BMI AI Backend"}

# =========================
# LOAD MODEL
# =========================
@app.on_event("startup")
def startup_event():
    global model
    print("üöÄ Loading model...")
    model = get_model()
    model.eval()
    print("‚úÖ Model ready")

# =========================
# PREDICT
# =========================
@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    try:
        # 1Ô∏è‚É£ Read image
        image_bytes = await file.read()
        if not image_bytes:
            return {
                "error": "empty_file",
                "message": "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û"
            }

        image = Image.open(io.BytesIO(image_bytes)).convert("RGB")

        # 2Ô∏è‚É£ Quality check (soft warning)
        ok, reason = quality_check(image)
        if not ok:
            print(f"‚ö†Ô∏è Quality warning: {reason}")

        # 3Ô∏è‚É£ Detect face (soft logic)
        face_image, face_found = detect_and_crop_face(image)

        # ‚ùó ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏•‡∏¢ + confidence ‡∏ï‡πà‡∏≥ ‚Üí ‡∏Ñ‡πà‡∏≠‡∏¢ reject
        # (‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏¢‡∏±‡∏á‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏•‡∏≠‡∏á‡∏Å‡πà‡∏≠‡∏ô)
        x = preprocess_image(face_image)
        x = x.to(next(model.parameters()).device)

        # 4Ô∏è‚É£ Predict
        with torch.no_grad():
            logits = model(x)
            probs = torch.softmax(logits, dim=1)

            cls_idx = int(probs.argmax(dim=1).item())
            confidence = float(probs[0, cls_idx])

        cls_name = BMI_LABELS.get(cls_idx)

        # 5Ô∏è‚É£ Hard reject ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Å‡∏£‡∏ì‡∏µ "‡πÑ‡∏°‡πà‡∏ô‡πà‡∏≤‡πÉ‡∏ä‡πà‡∏Ñ‡∏ô‡∏à‡∏£‡∏¥‡∏á ‡πÜ"
        if not face_found and confidence < 0.55:
            return {
                "error": "no_clear_face",
                "message": "‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏Ñ‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô"
            }

        # 6Ô∏è‚É£ Response (‡∏ù‡∏±‡πà‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ)
        return {
            "status": BMI_STATUS_TH[cls_name],
            "confidence": round(confidence, 3)
        }

    except Exception:
        traceback.print_exc()
        return {
            "error": "prediction_failed",
            "message": "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô BMI ‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏û‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ"
        }
