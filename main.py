from fastapi import FastAPI, UploadFile, File
from PIL import Image
import io
import traceback
import torch

from app.model import get_model
from app.utils import preprocess_image
from app.face_utils import detect_and_crop_face
from app.quality_check import quality_check

# =========================
# THAI LABEL
# =========================
BMI_STATUS_TH = {
    "under": "‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏Å‡∏ì‡∏ë‡πå",
    "normal": "‡∏™‡∏°‡∏™‡πà‡∏ß‡∏ô",
    "over": "‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏Å‡∏ì‡∏ë‡πå"
}

# =========================
# CLASS CONFIG (‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏£‡∏á‡∏ï‡∏≠‡∏ô train)
# =========================
BMI_LABELS = {
    0: ("under", 17.5),
    1: ("normal", 22.0),
    2: ("over", 27.5)
}

app = FastAPI()

# =========================
# GLOBAL MODEL
# =========================
model = None

# =========================
# HEALTH CHECK
# =========================
@app.get("/")
def health():
    return {"status": "ok", "service": "BMI AI Backend"}

# =========================
# LOAD MODEL
# =========================
@app.on_event("startup")
def startup_event():
    global model
    print("üöÄ Loading model...")
    model = get_model()
    model.eval()
    print("‚úÖ Model ready")

# =========================
# PREDICT
# =========================
@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    try:
        # 1Ô∏è‚É£ Read image
        image_bytes = await file.read()
        if not image_bytes:
            return {
                "error": "empty_file",
                "message": "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û"
            }

        image = Image.open(io.BytesIO(image_bytes)).convert("RGB")

        # 2Ô∏è‚É£ Quality check (‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡πÄ‡∏â‡∏¢ ‡πÜ ‡πÑ‡∏°‡πà‡∏ï‡∏±‡∏î)
        ok, reason = quality_check(image)
        if not ok:
            print(f"‚ö†Ô∏è Quality warning: {reason}")

        # 3Ô∏è‚É£ Detect & crop face
        face_image, face_found = detect_and_crop_face(image)

        if face_found:
            print("üôÇ ‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ ‚Üí ‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà crop")
        else:
            print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ ‚Üí ‡πÉ‡∏ä‡πâ‡∏ó‡∏±‡πâ‡∏á‡∏†‡∏≤‡∏û")

        # 4Ô∏è‚É£ Preprocess (224x224 ‡∏ï‡∏£‡∏á train)
        x = preprocess_image(face_image)
        x = x.to(next(model.parameters()).device)

        # 5Ô∏è‚É£ Predict (‡πÉ‡∏ä‡πâ‡∏ú‡∏•‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏•‡πâ‡∏ß‡∏ô ‡πÜ)
        with torch.no_grad():
            logits = model(x)
            probs = torch.softmax(logits, dim=1)

            cls_idx = int(probs.argmax(dim=1).item())
            cls_name, _ = BMI_LABELS[cls_idx]
            confidence = float(probs[0, cls_idx])

        # 6Ô∏è‚É£ Response (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ)
        return {
            "status": BMI_STATUS_TH[cls_name],
            "confidence": round(confidence, 3)
        }

    except Exception:
        traceback.print_exc()
        return {
            "error": "prediction_failed",
            "message": "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô BMI ‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏û‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ"
        }
