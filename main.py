from fastapi import FastAPI, UploadFile, File
from PIL import Image
import io
import traceback
import torch

from app.model import get_model
from app.utils import preprocess_image
from app.face_utils import detect_and_crop_face
from app.quality_check import quality_check

app = FastAPI()

# =========================
# GLOBAL MODEL
# =========================
model = None

# =========================
# CLASS CONFIG (‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏£‡∏á‡∏ï‡∏≠‡∏ô train)
# =========================
BMI_LABELS = {
    0: "under",
    1: "normal",
    2: "over"
}

BMI_STATUS_TH = {
    "under": "‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏Å‡∏ì‡∏ë‡πå",
    "normal": "‡∏™‡∏°‡∏™‡πà‡∏ß‡∏ô",
    "over": "‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏Å‡∏ì‡∏ë‡πå"
}

# =========================
# HEALTH CHECK
# =========================
@app.get("/")
def health():
    return {
        "status": "ok",
        "service": "BMI AI Backend"
    }

# =========================
# LOAD MODEL
# =========================
@app.on_event("startup")
def startup_event():
    global model
    print("üöÄ Loading model...")
    model = get_model()
    model.eval()
    print("‚úÖ Model ready")

# =========================
# PREDICT
# =========================
@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    try:
        # 1Ô∏è‚É£ Read image
        image_bytes = await file.read()
        if not image_bytes:
            return {
                "error": "empty_file",
                "message": "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û"
            }

        image = Image.open(io.BytesIO(image_bytes)).convert("RGB")

        # ‚ùó ‡∏Å‡∏±‡∏ô‡∏£‡∏π‡∏õ‡πÄ‡∏•‡πá‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô
        if image.width < 80 or image.height < 80:
            return {
                "error": "image_too_small",
                "message": "‡∏†‡∏≤‡∏û‡∏°‡∏µ‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ñ‡πà‡∏≤‡∏¢‡πÉ‡∏´‡∏°‡πà"
            }

        # 2Ô∏è‚É£ Quality gate
        quality_ok, reason = quality_check(image)
        if not quality_ok:
            return {
                "error": "bad_quality",
                "message": "‡∏†‡∏≤‡∏û‡πÑ‡∏°‡πà‡∏ä‡∏±‡∏î‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏™‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ñ‡πà‡∏≤‡∏¢‡πÉ‡∏´‡∏°‡πà"
            }

        # 3Ô∏è‚É£ Face gate (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å)
        face_image, has_face = detect_and_crop_face(image)
        if not has_face:
            return {
                "error": "no_face",
                "message": "‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡∏£‡∏á ‡πÑ‡∏°‡πà‡πÉ‡∏™‡πà‡∏´‡∏ô‡πâ‡∏≤‡∏Å‡∏≤‡∏Å"
            }

        # 4Ô∏è‚É£ Preprocess
        x = preprocess_image(face_image)
        x = x.to(next(model.parameters()).device)

        # 5Ô∏è‚É£ Predict
        with torch.no_grad():
            logits = model(x)
            probs = torch.softmax(logits, dim=1)

            cls_idx = int(probs.argmax(dim=1).item())
            cls_name = BMI_LABELS[cls_idx]
            confidence = float(probs[0, cls_idx])

        # üîç debug log (‡πÄ‡∏≠‡∏≤‡πÑ‡∏ß‡πâ‡∏î‡∏π bias)
        print("üß† PRED:", cls_name, confidence)

        # 6Ô∏è‚É£ Threshold ‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏°‡∏Ñ‡∏•‡∏≤‡∏™ (‡πÅ‡∏Å‡πâ under bias)
        class_thresholds = {
            "under": 0.60,
            "normal": 0.45,
            "over": 0.50
        }

        threshold = class_thresholds.get(cls_name, 0.5)

        if confidence < threshold:
            return {
                "error": "low_confidence",
                "message": "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û‡πÉ‡∏´‡∏°‡πà"
            }

        # 7Ô∏è‚É£ Final response
        return {
            "status": BMI_STATUS_TH[cls_name],
            "confidence": round(confidence, 3)
        }

    except Exception:
        traceback.print_exc()
        return {
            "error": "prediction_failed",
            "message": "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô BMI ‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏û‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ"
        }
